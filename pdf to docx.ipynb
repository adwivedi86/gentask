{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4afa7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RADHA\\\\Documents\\\\gentask'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5254c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: glob2 in c:\\users\\radha\\anaconda3\\lib\\site-packages (0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93585d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\radha\\anaconda3\\lib\\site-packages (3.12.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d3d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\radha\\anaconda3\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\radha\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\radha\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\radha\\anaconda3\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n",
    "!pip install PyPDF2\n",
    "!pip install --upgrade PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4334473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "def pdf_to_docx(pdf_path, docx_path):\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    document = Document()\n",
    "\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        document.add_paragraph(text)\n",
    "\n",
    "    document.save(docx_path)\n",
    "\n",
    "def convert_directory_pdf_to_docx(pdf_directory, docx_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(docx_directory):\n",
    "        os.makedirs(docx_directory)\n",
    "\n",
    "    # Get a list of PDF files in the input directory\n",
    "    pdf_files = glob.glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        # Construct the output file path\n",
    "        base_name = os.path.basename(pdf_file)\n",
    "        file_name = os.path.splitext(base_name)[0]\n",
    "        docx_file = os.path.join(docx_directory, f'{file_name}.docx')\n",
    "\n",
    "        # Convert the PDF file to DOCX\n",
    "        pdf_to_docx(pdf_file, docx_file)\n",
    "\n",
    "# Example usage\n",
    "pdf_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf'\n",
    "docx_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf2docx'\n",
    "\n",
    "convert_directory_pdf_to_docx(pdf_directory, docx_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61060a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 1 PDF files to DOCX...\n",
      "Processed file 1/1\n",
      "Conversion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "def pdf_to_docx(pdf_path, docx_path):\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    document = Document()\n",
    "\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        document.add_paragraph(text)\n",
    "\n",
    "    document.save(docx_path)\n",
    "\n",
    "def convert_directory_pdf_to_docx(pdf_directory, docx_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(docx_directory):\n",
    "        os.makedirs(docx_directory)\n",
    "\n",
    "    # Get a list of PDF files in the input directory\n",
    "    pdf_files = glob.glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "    total_files = len(pdf_files)\n",
    "    print(f\"Converting {total_files} PDF files to DOCX...\")\n",
    "\n",
    "    for idx, pdf_file in enumerate(pdf_files, 1):\n",
    "        # Construct the output file path\n",
    "        base_name = os.path.basename(pdf_file)\n",
    "        file_name = os.path.splitext(base_name)[0]\n",
    "        docx_file = os.path.join(docx_directory, f'{file_name}.docx')\n",
    "\n",
    "        # Convert the PDF file to DOCX\n",
    "        pdf_to_docx(pdf_file, docx_file)\n",
    "\n",
    "        # Print the progress\n",
    "        print(f\"Processed file {idx}/{total_files}\")\n",
    "\n",
    "    print(\"Conversion completed successfully!\")\n",
    "\n",
    "# Example usage\n",
    "pdf_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf'\n",
    "docx_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf2docx'\n",
    "\n",
    "convert_directory_pdf_to_docx(pdf_directory, docx_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5523983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 1 PDF files to DOCX...\n",
      "Processed file 1/1\n",
      "Conversion completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "import re\n",
    "\n",
    "def sanitize_text(text):\n",
    "    # Remove unsupported characters\n",
    "    sanitized_text = re.sub(r'[^\\x00-\\x7F]', '', text)\n",
    "    return sanitized_text\n",
    "\n",
    "def pdf_to_docx(pdf_path, docx_path):\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    document = Document()\n",
    "\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        sanitized_text = sanitize_text(text)\n",
    "        document.add_paragraph(sanitized_text)\n",
    "\n",
    "    document.save(docx_path)\n",
    "\n",
    "def convert_directory_pdf_to_docx(pdf_directory, docx_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(docx_directory):\n",
    "        os.makedirs(docx_directory)\n",
    "\n",
    "    # Get a list of PDF files in the input directory\n",
    "    pdf_files = glob.glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "\n",
    "    total_files = len(pdf_files)\n",
    "    print(f\"Converting {total_files} PDF files to DOCX...\")\n",
    "\n",
    "    for idx, pdf_file in enumerate(pdf_files, 1):\n",
    "        # Construct the output file path\n",
    "        base_name = os.path.basename(pdf_file)\n",
    "        file_name = os.path.splitext(base_name)[0]\n",
    "        docx_file = os.path.join(docx_directory, f'{file_name}.docx')\n",
    "\n",
    "        # Convert the PDF file to DOCX\n",
    "        pdf_to_docx(pdf_file, docx_file)\n",
    "\n",
    "        # Print the progress\n",
    "        print(f\"Processed file {idx}/{total_files}\")\n",
    "\n",
    "    print(\"Conversion completed successfully!\")\n",
    "\n",
    "# Example usage\n",
    "pdf_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf'\n",
    "docx_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf2docx'\n",
    "\n",
    "convert_directory_pdf_to_docx(pdf_directory, docx_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2989fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "# import spacy\n",
    "# from docx.oxml.ns import nsdecls\n",
    "# from docx.oxml import parse_xml\n",
    "# from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "# # Load the custom NER model\n",
    "# nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "# def extract_custom_ner_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extract custom NER entities from text\n",
    "#     \"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     custom_ner_entities = []\n",
    "#     for ent in doc.ents:\n",
    "#         custom_ner_entities.append((ent.label_, ent.text))\n",
    "#     return custom_ner_entities\n",
    "\n",
    "# def redact_matching_data(paragraph, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in a paragraph\n",
    "#     \"\"\"\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         for run in paragraph.runs:\n",
    "#             if entity_text in run.text:\n",
    "#                 run_text = run.text.replace(entity_text, \"[REDACTED]\")\n",
    "#                 run.clear()  # Remove the existing run\n",
    "#                 new_run = paragraph.add_run(run_text)  # Create a new run with the redacted text\n",
    "#                 font = new_run.font\n",
    "#                 font.highlight_color = docx.enum.text.WD_COLOR_INDEX.BLACK  # Apply black highlight color for redacted text\n",
    "\n",
    "# def redact_docx_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a DOCX file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(input_file)\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text = paragraph.text\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redact_matching_data(paragraph, matched_entities)\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_pdf_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a PDF file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     pdf_reader = PdfFileReader(input_file)\n",
    "#     pdf_writer = PdfFileWriter()\n",
    "\n",
    "#     for page_num in range(pdf_reader.numPages):\n",
    "#         page = pdf_reader.getPage(page_num)\n",
    "#         text = page.extract_text()\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redacted_text = text\n",
    "\n",
    "#         for entity_label, entity_text in matched_entities:\n",
    "#             redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "\n",
    "#         page = page.extract_text().replace(text, redacted_text)\n",
    "#         pdf_writer.addPage(page)\n",
    "\n",
    "#     with open(output_file, 'wb') as output_pdf:\n",
    "#         pdf_writer.write(output_pdf)\n",
    "\n",
    "# def redact_files_in_directory(input_directory, output_directory):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_directory, exist_ok=True)\n",
    "#     files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "#     for file in files:\n",
    "#         file_ext = os.path.splitext(file)[1].lower()\n",
    "#         file_name = os.path.basename(file)\n",
    "#         output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "#         if file_ext == \".docx\":\n",
    "#             redact_docx_file(file, output_file)\n",
    "#             print(f\"Redacted DOCX file saved: {output_file}\")\n",
    "#         elif file_ext == \".pdf\":\n",
    "#             redact_pdf_file(file, output_file)\n",
    "#             print(f\"Redacted PDF file saved: {output_file}\")\n",
    "\n",
    "# # Specify the input and output directories\n",
    "# input_directory = '/home/ec2-user/SageMaker/synthetic_resumes3/'\n",
    "# output_directory = '/home/ec2-user/SageMaker/syn_redact/'\n",
    "\n",
    "# # Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "# redact_files_in_directory(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50219f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "# import spacy\n",
    "# from docx.oxml.ns import nsdecls\n",
    "# from docx.oxml import parse_xml\n",
    "# from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "# # Load the custom NER model\n",
    "# nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "# def extract_custom_ner_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extract custom NER entities from text\n",
    "#     \"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     custom_ner_entities = []\n",
    "#     for ent in doc.ents:\n",
    "#         custom_ner_entities.append((ent.label_, ent.text))\n",
    "#     return custom_ner_entities\n",
    "\n",
    "# def redact_matching_data(paragraph, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in a paragraph\n",
    "#     \"\"\"\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         for run in paragraph.runs:\n",
    "#             if entity_text in run.text:\n",
    "#                 run_text = run.text.replace(entity_text, \"[REDACTED]\")\n",
    "#                 run.clear()  # Remove the existing run\n",
    "#                 new_run = paragraph.add_run(run_text)  # Create a new run with the redacted text\n",
    "#                 font = new_run.font\n",
    "#                 font.highlight_color = docx.enum.text.WD_COLOR_INDEX.BLACK  # Apply black highlight color for redacted text\n",
    "\n",
    "# def redact_docx_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a DOCX file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(input_file)\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text = paragraph.text\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redact_matching_data(paragraph, matched_entities)\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_pdf_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a PDF file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     pdf_reader = PdfFileReader(input_file)\n",
    "#     pdf_writer = PdfFileWriter()\n",
    "\n",
    "#     for page_num in range(pdf_reader.numPages):\n",
    "#         page = pdf_reader.getPage(page_num)\n",
    "#         text = page.extractText()\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redacted_text = text\n",
    "\n",
    "#         for entity_label, entity_text in matched_entities:\n",
    "#             redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "\n",
    "#         page = page.extractText().replace(text, redacted_text)\n",
    "#         pdf_writer.addPage(page)\n",
    "\n",
    "#     with open(output_file, 'wb') as output_pdf:\n",
    "#         pdf_writer.write(output_pdf)\n",
    "\n",
    "# def redact_files_in_directory(input_directory, output_directory):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_directory, exist_ok=True)\n",
    "#     files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "#     for file in files:\n",
    "#         file_ext = os.path.splitext(file)[1].lower()\n",
    "#         file_name = os.path.basename(file)\n",
    "#         output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "#         if file_ext == \".docx\":\n",
    "#             redact_docx_file(file, output_file)\n",
    "#             print(f\"Redacted DOCX file saved: {output_file}\")\n",
    "#         elif file_ext == \".pdf\":\n",
    "#             redact_pdf_file(file, output_file)\n",
    "#             print(f\"Redacted PDF file saved: {output_file}\")\n",
    "\n",
    "# # Specify the input and output directories\n",
    "# input_directory = '/home/ec2-user/SageMaker/synthetic_resumes3/'\n",
    "# output_directory = '/home/ec2-user/SageMaker/syn_redact/'\n",
    "\n",
    "# # Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "# redact_files_in_directory(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f0090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "# import spacy\n",
    "# from docx.oxml.ns import nsdecls\n",
    "# from docx.oxml import parse_xml\n",
    "# from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "# # Load the custom NER model\n",
    "# nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "# def extract_custom_ner_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extract custom NER entities from text\n",
    "#     \"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     custom_ner_entities = []\n",
    "#     for ent in doc.ents:\n",
    "#         custom_ner_entities.append((ent.label_, ent.text))\n",
    "#     return custom_ner_entities\n",
    "\n",
    "# def redact_matching_data(paragraph, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in a paragraph\n",
    "#     \"\"\"\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         for run in paragraph.runs:\n",
    "#             if entity_text in run.text:\n",
    "#                 run_text = run.text.replace(entity_text, \"[REDACTED]\")\n",
    "#                 run.clear()  # Remove the existing run\n",
    "#                 new_run = paragraph.add_run(run_text)  # Create a new run with the redacted text\n",
    "#                 font = new_run.font\n",
    "#                 font.highlight_color = docx.enum.text.WD_COLOR_INDEX.BLACK  # Apply black highlight color for redacted text\n",
    "\n",
    "# def redact_docx_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a DOCX file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(input_file)\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text = paragraph.text\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redact_matching_data(paragraph, matched_entities)\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_pdf_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a PDF file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     pdf_reader = PdfFileReader(input_file)\n",
    "#     pdf_writer = PdfFileWriter()\n",
    "\n",
    "#     for page_num in range(pdf_reader.getNumPages()):\n",
    "#         page = pdf_reader.getPage(page_num)\n",
    "#         text = page.extractText()\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redacted_text = text\n",
    "\n",
    "#         for entity_label, entity_text in matched_entities:\n",
    "#             redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "\n",
    "#         page.mergePage(redacted_text)\n",
    "#         pdf_writer.addPage(page)\n",
    "\n",
    "#     with open(output_file, 'wb') as output_pdf:\n",
    "#         pdf_writer.write(output_pdf)\n",
    "\n",
    "# def redact_files_in_directory(input_directory, output_directory):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_directory, exist_ok=True)\n",
    "#     files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "#     for file in files:\n",
    "#         file_ext = os.path.splitext(file)[1].lower()\n",
    "#         file_name = os.path.basename(file)\n",
    "#         output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "#         if file_ext == \".docx\":\n",
    "#             redact_docx_file(file, output_file)\n",
    "#             print(f\"Redacted DOCX file saved: {output_file}\")\n",
    "#         elif file_ext == \".pdf\":\n",
    "#             redact_pdf_file(file, output_file)\n",
    "#             print(f\"Redacted PDF file saved: {output_file}\")\n",
    "\n",
    "# # Specify the input and output directories\n",
    "# input_directory = '/home/ec2-user/SageMaker/synthetic_resumes3/'\n",
    "# output_directory = '/home/ec2-user/SageMaker/syn_redact/'\n",
    "\n",
    "# # Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "# redact_files_in_directory(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c414cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "# import spacy\n",
    "# from PyPDF4 import PdfFileReader, PdfFileWriter\n",
    "\n",
    "# # Load the custom NER model\n",
    "# nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "# def extract_custom_ner_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extract custom NER entities from text\n",
    "#     \"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     custom_ner_entities = []\n",
    "#     for ent in doc.ents:\n",
    "#         custom_ner_entities.append((ent.label_, ent.text))\n",
    "#     return custom_ner_entities\n",
    "\n",
    "# def redact_matching_data(paragraph, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in a paragraph\n",
    "#     \"\"\"\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         for run in paragraph.runs:\n",
    "#             if entity_text in run.text:\n",
    "#                 run_text = run.text.replace(entity_text, \"[REDACTED]\")\n",
    "#                 run.clear()  # Remove the existing run\n",
    "#                 new_run = paragraph.add_run(run_text)  # Create a new run with the redacted text\n",
    "#                 font = new_run.font\n",
    "#                 font.highlight_color = docx.enum.text.WD_COLOR_INDEX.BLACK  # Apply black highlight color for redacted text\n",
    "\n",
    "# def redact_docx_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a DOCX file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(input_file)\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text = paragraph.text\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redact_matching_data(paragraph, matched_entities)\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_pdf_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a PDF file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     pdf_reader = PdfFileReader(input_file)\n",
    "#     pdf_writer = PdfFileWriter()\n",
    "\n",
    "#     for page_num in range(pdf_reader.getNumPages()):\n",
    "#         page = pdf_reader.getPage(page_num)\n",
    "#         text = page.extractText()\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redacted_text = text\n",
    "\n",
    "#         for entity_label, entity_text in matched_entities:\n",
    "#             redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "\n",
    "#         page.mergePage(redacted_text)\n",
    "#         pdf_writer.addPage(page)\n",
    "\n",
    "#     with open(output_file, 'wb') as output_pdf:\n",
    "#         pdf_writer.write(output_pdf)\n",
    "\n",
    "# def redact_files_in_directory(input_directory, output_directory):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_directory, exist_ok=True)\n",
    "#     files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "#     for file in files:\n",
    "#         file_ext = os.path.splitext(file)[1].lower()\n",
    "#         file_name = os.path.basename(file)\n",
    "#         output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "#         if file_ext == \".docx\":\n",
    "#             text = read_docx_file(file)\n",
    "#             matched_entities = extract_custom_ner_entities(text)\n",
    "#             redacted_text = redact_text(text, matched_entities)\n",
    "#             save_redacted_docx(output_file, redacted_text)\n",
    "#             print(f\"Redacted DOCX file saved: {output_file}\")\n",
    "#         elif file_ext == \".pdf\":\n",
    "#             text = read_pdf_file(file)\n",
    "#             matched_entities = extract_custom_ner_entities(text)\n",
    "#             redacted_text = redact_text(text, matched_entities)\n",
    "#             save_redacted_pdf(output_file, redacted_text)\n",
    "#             print(f\"Redacted PDF file saved: {output_file}\")\n",
    "\n",
    "# def read_docx_file(file_path):\n",
    "#     \"\"\"\n",
    "#     Read the content of a DOCX file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(file_path)\n",
    "#     content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "#     return content\n",
    "\n",
    "# def read_pdf_file(file_path):\n",
    "#     \"\"\"\n",
    "#     Read the content of a PDF file\n",
    "#     \"\"\"\n",
    "#     with open(file_path, 'rb') as file:\n",
    "#         pdf_reader = PdfFileReader(file)\n",
    "#         content = \"\"\n",
    "#         for page_num in range(pdf_reader.getNumPages()):\n",
    "#             page = pdf_reader.getPage(page_num)\n",
    "#             content += page.extract_text()\n",
    "#     return content\n",
    "\n",
    "# def redact_text(text, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in the text\n",
    "#     \"\"\"\n",
    "#     redacted_text = text\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "#     return redacted_text\n",
    "\n",
    "# def save_redacted_docx(file_path, redacted_text):\n",
    "#     \"\"\"\n",
    "#     Save the redacted text as a DOCX file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document()\n",
    "#     doc.add_paragraph(redacted_text)\n",
    "#     doc.save(file_path)\n",
    "\n",
    "# def save_redacted_pdf(file_path, redacted_text):\n",
    "#     \"\"\"\n",
    "#     Save the redacted text as a PDF file\n",
    "#     \"\"\"\n",
    "#     pdf_writer = PdfFileWriter()\n",
    "#     pdf_writer.addPage(redacted_text)\n",
    "#     with open(file_path, 'wb') as output_pdf:\n",
    "#         pdf_writer.write(output_pdf)\n",
    "\n",
    "# # Specify the input and output directories\n",
    "# input_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf'\n",
    "# output_directory = r'C:\\Users\\RADHA\\Documents\\gentask\\samplepdf2docx'\n",
    "\n",
    "\n",
    "# # Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "# redact_files_in_directory(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee63c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model './model-last'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the custom NER model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./model-last\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_custom_ner_entities\u001b[39m(text):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    Extract custom NER entities from text\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model './model-last'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "# import spacy\n",
    "# import fitz\n",
    "\n",
    "# # Load the custom NER model\n",
    "# nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "# def extract_custom_ner_entities(text):\n",
    "#     \"\"\"\n",
    "#     Extract custom NER entities from text\n",
    "#     \"\"\"\n",
    "#     doc = nlp(text)\n",
    "#     custom_ner_entities = []\n",
    "#     for ent in doc.ents:\n",
    "#         custom_ner_entities.append((ent.label_, ent.text))\n",
    "#     return custom_ner_entities\n",
    "\n",
    "# def redact_matching_data(paragraph, matched_entities):\n",
    "#     \"\"\"\n",
    "#     Redact matching entities in a paragraph\n",
    "#     \"\"\"\n",
    "#     for entity_label, entity_text in matched_entities:\n",
    "#         for run in paragraph.runs:\n",
    "#             if entity_text in run.text:\n",
    "#                 run_text = run.text.replace(entity_text, \"[REDACTED]\")\n",
    "#                 run.clear()  # Remove the existing run\n",
    "#                 new_run = paragraph.add_run(run_text)  # Create a new run with the redacted text\n",
    "#                 font = new_run.font\n",
    "#                 font.highlight_color = docx.enum.text.WD_COLOR_INDEX.BLACK  # Apply black highlight color for redacted text\n",
    "\n",
    "# def redact_docx_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a DOCX file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = docx.Document(input_file)\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         text = paragraph.text\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redact_matching_data(paragraph, matched_entities)\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_pdf_file(input_file, output_file):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in a PDF file and save the redacted file\n",
    "#     \"\"\"\n",
    "#     doc = fitz.open(input_file)\n",
    "\n",
    "#     for page_num in range(doc.page_count):\n",
    "#         page = doc.load_page(page_num)\n",
    "#         text = page.get_text()\n",
    "#         matched_entities = extract_custom_ner_entities(text)\n",
    "#         redacted_text = text\n",
    "\n",
    "#         for entity_label, entity_text in matched_entities:\n",
    "#             redacted_text = redacted_text.replace(entity_text, \"[REDACTED]\")\n",
    "\n",
    "#         page.add_redact_annot(fitz.Rect(0, 0, page.rect.width, page.rect.height), text_color=(0, 0, 0))\n",
    "#         page.apply_redactions()\n",
    "\n",
    "#     doc.save(output_file)\n",
    "\n",
    "# def redact_files_in_directory(input_directory, output_directory):\n",
    "#     \"\"\"\n",
    "#     Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "#     \"\"\"\n",
    "#     os.makedirs(output_directory, exist_ok=True)\n",
    "#     files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "#     for file in files:\n",
    "#         file_ext = os.path.splitext(file)[1].lower()\n",
    "#         file_name = os.path.basename(file)\n",
    "#         output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "#         if file_ext == \".docx\":\n",
    "#             redact_docx_file(file, output_file)\n",
    "#             print(f\"Redacted DOCX file saved: {output_file}\")\n",
    "#         elif file_ext == \".pdf\":\n",
    "#             redact_pdf_file(file, output_file)\n",
    "#             print(f\"Redacted PDF file saved: {output_file}\")\n",
    "\n",
    "# # Specify the input and output directories\n",
    "# input_directory = r'/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1'\n",
    "# output_directory = r'/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1/samplepdf2docx'\n",
    "\n",
    "# # Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "# redact_files_in_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redact either pdf or docx\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import docx\n",
    "import spacy\n",
    "import fitz\n",
    "from typing import Tuple\n",
    "from io import BytesIO\n",
    "\n",
    "# Specify the input and output directories\n",
    "input_directory = r'/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1'\n",
    "output_directory = r'/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1/samplepdf2docx'\n",
    "\n",
    "# Load the custom NER model\n",
    "nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "def extract_custom_ner_entities(text):\n",
    "    \"\"\"\n",
    "    Extract custom NER entities from text\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    custom_ner_entities = []\n",
    "    for ent in doc.ents:\n",
    "        custom_ner_entities.append((ent.label_, ent.text))\n",
    "    return custom_ner_entities\n",
    "\n",
    "def redact_matching_data(page, matched_entities):\n",
    "    \"\"\"\n",
    "    Redact matching entities in a page (PDF) or paragraph (DOCX)\n",
    "    \"\"\"\n",
    "    matches_found = 0\n",
    "    if isinstance(page, fitz.Page):  # For PDF files\n",
    "        for entity_label, entity_text in matched_entities:\n",
    "            matching_entity_area = page.search_for(entity_text)\n",
    "            # Redact matching entities\n",
    "            for area in matching_entity_area:\n",
    "                page.add_redact_annot(area)\n",
    "                matches_found += 1\n",
    "        # Apply the redaction\n",
    "        page.apply_redactions()\n",
    "    elif isinstance(page, docx.text.paragraph.Paragraph):  # For DOCX files\n",
    "        for entity_label, entity_text in matched_entities:\n",
    "            if entity_text in page.text:\n",
    "                page_text = page.text.replace(entity_text, \"[REDACTED]\")\n",
    "                page.clear()  # Remove the existing text\n",
    "                page.add_run(page_text)  # Add the redacted text\n",
    "                matches_found += 1\n",
    "    return matches_found\n",
    "\n",
    "def process_data(input_file: str, output_file: str, pages: Tuple = None, action: str = 'Redact'):\n",
    "    \"\"\"\n",
    "    Process the PDF or DOCX file and perform redaction\n",
    "    \"\"\"\n",
    "    file_ext = os.path.splitext(input_file)[1].lower()\n",
    "\n",
    "    if file_ext == \".pdf\":\n",
    "        # Open the PDF\n",
    "        pdfDoc = fitz.open(input_file, filetype=\"pdf\")\n",
    "        # Save the generated PDF to memory buffer\n",
    "        output_buffer = BytesIO()\n",
    "        total_matches = 0\n",
    "        # Iterate through pages\n",
    "        for pg in range(pdfDoc.page_count):\n",
    "            # If required for specific pages\n",
    "            if pages:\n",
    "                if str(pg) not in pages:\n",
    "                    continue\n",
    "            # Select the page\n",
    "            page = pdfDoc[pg]\n",
    "            # Get page text\n",
    "            page_text = page.get_text(\"text\")\n",
    "            # Extract custom NER entities from page text\n",
    "            custom_entities = extract_custom_ner_entities(page_text)\n",
    "            # Perform redaction based on extracted custom entities\n",
    "            matches_found = redact_matching_data(page, custom_entities)\n",
    "            total_matches += matches_found\n",
    "        \n",
    "        print(f\"{total_matches} Match(es) Found of PII Attributes In Input File: {input_file}\")\n",
    "        # Save to output\n",
    "        pdfDoc.save(output_buffer)\n",
    "        pdfDoc.close()\n",
    "        # Save the output buffer to the output file\n",
    "        with open(output_file, mode='wb') as f:\n",
    "            f.write(output_buffer.getbuffer())\n",
    "\n",
    "    elif file_ext == \".docx\":\n",
    "        doc = docx.Document(input_file)\n",
    "\n",
    "        total_matches = 0\n",
    "        for paragraph in doc.paragraphs:\n",
    "            text = paragraph.text\n",
    "            custom_entities = extract_custom_ner_entities(text)\n",
    "            matches_found = redact_matching_data(paragraph, custom_entities)\n",
    "            total_matches += matches_found\n",
    "\n",
    "        print(f\"{total_matches} Match(es) Found of PII Attributes In Input File: {input_file}\")\n",
    "        doc.save(output_file)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_ext}\")\n",
    "\n",
    "def redact_files_in_directory(input_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "    \"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    files = glob.glob(os.path.join(input_directory, \"*.*\"))\n",
    "\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file)\n",
    "        output_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "        process_data(file, output_file)\n",
    "        print(f\"Redacted file saved: {output_file}\")\n",
    "\n",
    "# Redact custom NER entities in all PDF and DOCX files in the input directory and save the redacted files in the output directory\n",
    "redact_files_in_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8498606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display text from pdf or docx\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from docx import Document\n",
    "import fitz\n",
    "\n",
    "# Set the path to the directory containing the files\n",
    "mypath = '/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1/'\n",
    "\n",
    "# Load the spacy model\n",
    "nlp = spacy.load(\"./model-last\")\n",
    "\n",
    "def SpacyMultiDoc(mypath):\n",
    "    custom_ner_entities = []\n",
    "    for file in glob.glob(mypath + \"/*.*\"):\n",
    "        file_ext = file.lower().split(\".\")[-1]\n",
    "        \n",
    "        if file_ext == 'pdf':\n",
    "            doc = fitz.open(file)\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "            doc.close()\n",
    "            \n",
    "        elif file_ext == 'docx':\n",
    "            doc = Document(file)\n",
    "            paragraphs = [p.text for p in doc.paragraphs]\n",
    "            text = ' '.join(paragraphs)\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        text = text.replace('\\n', ' ')\n",
    "        text = text.replace('\\t', ' ')\n",
    "        text = text.replace('\\r', ' ')\n",
    "        text = text.replace('\\xa0', ' ')\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        doc = nlp(text)\n",
    "        displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "        entities = [(ent.label_, ent.text) for ent in doc.ents]\n",
    "        for ent in doc.ents:\n",
    "            custom_ner_entities.append((ent.label_, ent.text))\n",
    "    \n",
    "    return custom_ner_entities\n",
    "\n",
    "custom_ner_entities = SpacyMultiDoc(mypath)\n",
    "print(custom_ner_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pdf to text merge all files\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_directory_to_text(directory_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            text = pdf_to_text(pdf_path)\n",
    "            all_text += text\n",
    "\n",
    "    # Save merged text to a single file\n",
    "    merged_output_path = os.path.join(directory_path, \"merged_text.txt\")\n",
    "    with open(merged_output_path, 'w', encoding='utf-8') as merged_output_file:\n",
    "        merged_output_file.write(all_text)\n",
    "\n",
    "\n",
    "# Provide the directory path where the PDF files are located\n",
    "directory_path = '/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1'\n",
    "\n",
    "convert_directory_to_text(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fde284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# either through pdf or text\n",
    "import os\n",
    "import fitz\n",
    "import docx\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "def docx_to_text(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "def convert_directory_to_text(directory_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            text = pdf_to_text(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            text = docx_to_text(file_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        all_text += text\n",
    "\n",
    "    # Save merged text to a single file\n",
    "    merged_output_path = os.path.join(directory_path, \"merged_text.txt\")\n",
    "    with open(merged_output_path, 'w', encoding='utf-8') as merged_output_file:\n",
    "        merged_output_file.write(all_text)\n",
    "\n",
    "# Provide the directory path where the files are located\n",
    "directory_path = '/content/drive/MyDrive/customPIIredaction-main/synthetic_resumes1'\n",
    "\n",
    "convert_directory_to_text(directory_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
